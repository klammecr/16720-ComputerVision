{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfeda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "id": "heavy-offset",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0f77a2caae79d1b262cbe6a16814af8",
     "grade": false,
     "grade_id": "q3-code1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "import nbimporter\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "import numpy as np\n",
    "\n",
    "from q2 import briefLite, briefMatch, plotMatches\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-sending",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "872c2a67000211f6ee78743fc74d2f27",
     "grade": false,
     "grade_id": "q3-note1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3: Homography Computation (30 pts)\n",
    "\n",
    "### 3.1 Computing the Homography (10 points)\n",
    "\n",
    "Write a function $\\texttt{computeH}$ that estimates the planar homography from a set of matched point pairs.\n",
    "\n",
    "\\begin{equation}\n",
    "\\texttt{function [H2to1] = computeH(p1, p2)}\n",
    "\\end{equation}\n",
    "\n",
    "$\\texttt{p1}$ and $\\texttt{p2}$ are $2\\times N$ matrices containing the coordinates $(x, y)$ of point pairs between the two images. $\\texttt{H2to1}$ should be a $3\\times 3$ matrix for the best homography from image 2 to image 1 in the least-square sense. This should follow from your matrix as derived in **Q 1.2**. For the solver, feel free to use whatever you like. Although the [svdnotes]() (SVD notes in at the end of this handout) are one of the more straightforward methods."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "id": "successful-premiere",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7238ebb6411b831b03c9191c9ad717a2",
     "grade": false,
     "grade_id": "q3-code2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def computeH(p1, p2):\n",
    "    \"\"\"\n",
    "    Compute the homography matrix from point correspondences.\n",
    "    \n",
    "    INPUTS:\n",
    "        p1 and p2 - Each are size (2 x N) matrices of corresponding (x, y)'  \n",
    "                 coordinates between two images\n",
    "    OUTPUTS:\n",
    "     H2to1 - a 3 x 3 matrix encoding the homography that best matches the linear \n",
    "            equation\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    assert p1.shape[1] == p2.shape[1]\n",
    "    assert p1.shape[0] == 2\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return H2to1"
=======
    "    # p1 = H*p2\n",
    "    assert p1.shape[1] == p2.shape[1]\n",
    "    assert p1.shape[0] == 2\n",
    "    \n",
    "    A = np.zeros((2*p1.shape[1], 9))\n",
    "    for i in range(p1.shape[1]):\n",
    "        # Extract the points\n",
    "        q_i = p2[:, i]\n",
    "        qx  = q_i[0]\n",
    "        qy  = q_i[1]\n",
    "\n",
    "        p_i = p1[:, i]\n",
    "        px = p_i[0]\n",
    "        py = p_i[1]\n",
    "\n",
    "\n",
    "        # Place the points into the matrix\n",
    "        A[2*i]   = np.array([qx, qy, 1, 0, 0, 0, -qx*px, -qy*px, -px])\n",
    "        A[2*i+1] = np.array([0, 0, 0, qx, qy, 1, -qx*py, -qy*py, -py])\n",
    "\n",
    "   \n",
    "    U, sigma, Vt = np.linalg.svd(A)\n",
    "    # Take the last row of Vt or the last column of V\n",
    "    H2to1 = Vt[-1].reshape(3,3)\n",
    "\n",
    "    return H2to1/H2to1[-1,-1]"
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "id": "naked-documentation",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9eff761fef7004ed59e6d17f2aa2323",
     "grade": true,
     "grade_id": "q3_1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.89362281 260.35984853]\n"
     ]
    }
   ],
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "source": [
    "### HIDDEN TEST CELL\n",
    "# Hint: Be careful that your homography matrix should be a mapping from\n",
    "# p2 to p1: p1 = H*P2\n",
    "im1 = cv2.imread(\"data/incline_L.png\")\n",
<<<<<<< HEAD
    "im2 = cv2.imread(\"data/incline_R.png\")"
=======
    "im2 = cv2.imread(\"data/incline_R.png\")\n",
    "\n",
    "# Find the locations of the feature matches\n",
    "locs1, desc1 = briefLite(im1)\n",
    "locs2, desc2 = briefLite(im2)\n",
    "matches = briefMatch(desc1, desc2)\n",
    "\n",
    "# Get the first four matches\n",
    "# matches = matches[:4]\n",
    "\n",
    "np_matches = np.array(matches)\n",
    "\n",
    "p1 = locs1[np_matches[:, 0]].T\n",
    "p2 = locs2[np_matches[:, 1]].T\n",
    "H = computeH(p1, p2)\n",
    "\n",
    "# Test the transformation of one of the points\n",
    "for i in range(1):\n",
    "    p1_est = H@np.append(p2[:, i], [1])\n",
    "    print(p1_est[0:2]/[p1_est[-1]]-p1[:, i])"
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-damages",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87eaa423b4050e5dfe0860614ff82d1a",
     "grade": false,
     "grade_id": "q3-note2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 RANSAC (10 points)\n",
    "\n",
    "The RANSAC algorithm can generally fit any model to noisy data. You will implement it for (planar) homographies between images.\n",
    "\n",
    "Write a function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\texttt{function [bestH2to1, inliers] = computeH_ransac(locs1, locs2)}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\texttt{bestH2to1}$ should be the homography $\\mathbf{H}$ with most inliers found during RANSAC.  $\\mathbf{H}$ will be a homography such that if $\\mathbf{p}_2$ is a point in $\\texttt{locs2}$ and  $\\mathbf{p}_1$ is the corresponding point in $\\texttt{locs1}$, then $\\mathbf{p}_1 \\equiv \\mathbf{Hp}_2$. $\\texttt{locs1}$ and $\\texttt{locs2}$ are $N\\times 2$ matrices containing the matched points. $\\texttt{inliers}$ is a vector of length $N$ with a 1 at those matches that are part of the consensus set, and 0 elsewhere."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "id": "governing-infrastructure",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b94870760b906217cfc5493765f6f6d",
     "grade": false,
     "grade_id": "q2-code3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def computeH_ransac(matches, locs1, locs2, num_iter=5000, tol=2):\n",
    "    \"\"\"\n",
    "    Returns the best homography by computing the best set of matches using RANSAC.\n",
    "    \n",
    "    INPUTS\n",
    "        matches - matrix specifying matches between these two sets of point locations\n",
    "        locs1 and locs2 - matrices specifying point locations in each of the images\n",
    "        num_iter - number of iterations to run RANSAC\n",
    "        tol - tolerance value for considering a point to be an inlier\n",
    "\n",
    "    OUTPUTS\n",
    "        bestH2to1 - homography matrix with the most inliers found during RANSAC\n",
    "        inliers - a vector of length N (len(matches)) with 1 at the those matches\n",
    "                  that are part of the consensus set, and 0 elsewhere.\n",
    "    \"\"\"\n",
    "    p1 = locs1[matches[:, 0], :]\n",
    "    p1 = np.transpose(p1)\n",
    "    p2 = locs2[matches[:, 1], :]\n",
    "    p2 = np.transpose(p2)\n",
<<<<<<< HEAD
    "    p2_homo = np.concatenate((p2, np.ones([1, p2.shape[1]])), axis=0)\n",
=======
    "    p1_homo = np.concatenate((p1, np.ones([1, p1.shape[1]])), axis=0)\n",
    "    p2_homo = np.concatenate((p2, np.ones([1, p2.shape[1]])), axis=0)\n",
    "\n",
    "    best_num_inliers = 0\n",
    "    inliers = np.zeros((matches.shape[0]))\n",
    "    bestH = np.eye(3)\n",
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
    "    \n",
    "    # Hint: For each iteration, sample 4 point pairs for solving H using \"computeH()\".\n",
    "    # Then, compute the number of inliers using the threshold. Finally, pick the H with\n",
    "    # the most inliers.\n",
    "    # Note: Please don't fix the random seed.  We need to use different random seeds to\n",
    "    # validate your implementation.\n",
<<<<<<< HEAD
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return bestH2to1, inliers"
=======
    "    for i in range(num_iter):\n",
    "        # Randomly sample four points\n",
    "        sample_idxs = np.random.randint(0, p1.shape[1], 4)\n",
    "\n",
    "        # Get the four point correspondences\n",
    "        p1_samples = p1_homo[:, sample_idxs]\n",
    "        p2_samples = p2_homo[:, sample_idxs]\n",
    "\n",
    "        # Get the H matrix\n",
    "        H = computeH(p1_samples[0:2], p2_samples[0:2])\n",
    "\n",
    "        # Perform the warp and find the error\n",
    "        p1_estimate = H @ p2_homo\n",
    "        p1_estimate /= p1_estimate[-1]\n",
    "\n",
    "        # See if they are inliers\n",
    "        inlier = np.sqrt(np.sum((p1_estimate - p1_homo)**2, axis = 0)) < tol\n",
    "\n",
    "        num_inliers = np.sum(inlier.astype('int'))\n",
    "\n",
    "        if num_inliers > best_num_inliers:\n",
    "            best_num_inliers = num_inliers\n",
    "            bestH = H\n",
    "            inliers[np.where(inlier == 1)] = 1\n",
    "\n",
    "    return bestH, inliers"
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "id": "acceptable-publication",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23f41d61b82391a5dbb8d4d8fc72a8f5",
     "grade": true,
     "grade_id": "q3_2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN TEST CELL\n",
    "# Hint: When the number of iteration is small (e.g. 10), ideally, the number of inliers\n",
    "# should not be always the same if you call \"computeH_ransac()\" several times.\n",
    "im1 = cv2.imread(\"data/incline_L.png\")\n",
<<<<<<< HEAD
    "im2 = cv2.imread(\"data/incline_R.png\")"
=======
    "im2 = cv2.imread(\"data/incline_R.png\")\n",
    "\n",
    "# Find the locations of the feature matches\n",
    "locs1, desc1 = briefLite(im1)\n",
    "locs2, desc2 = briefLite(im2)\n",
    "matches = briefMatch(desc1, desc2)\n",
    "\n",
    "# Get the first four matches\n",
    "# matches = matches[:4]\n",
    "\n",
    "np_matches = np.array(matches)\n",
    "\n",
    "H, inliers = computeH_ransac(np_matches, locs1, locs2)\n",
    "\n",
    "warped = cv2.warpPerspective(im2, H, (im1.shape[1], im1.shape[0]))\n",
    "cv2.imshow(\"Warped Incline\", warped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-sterling",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ce1bc7b55de4216860019fa7d169132",
     "grade": false,
     "grade_id": "q3-note3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 Automated Homography Estimation/Warping for Augmented Reality (10 points)\n",
    "\n",
    "Implement the following steps: \n",
    "   1. Reads $\\texttt{cv_cover.jpg}$, $\\texttt{cv_desk.png}$, and $\\texttt{hp_cover.jpg}$.\n",
    "   2. Computes a homography automatically using $\\texttt{computeH_ransac}$.\n",
    "   3. Warps $\\texttt{hp_cover.jpg}$ to the dimensions of the $\\texttt{cv_desk.png}$ image using the OpenCV $\\texttt{warpPerspective}$ function. \n",
    "   4. At this point you should notice that although the image is being warped to the correct location, it is not filling up the same space as the book. Why do you think this is happening? How would you modify $\\texttt{hp_cover.jpg}$ to fix this issue?\n",
    "   5. Implement the function: $\\texttt{function [ composite_img ] = compositeH( H2to1, template, img) }$ to now compose this warped image with the desk image as in the following figures.\n",
    "   6. **The question will be manually graded.** Include your resulting image in your write-up. Please also print the final H matrix in your writeup (normalized so the bottom right value is 1)\n",
    "   \n",
    "|<img align=\"center\" src=\"figure/cv_desk.png\" width=\"300\"> | <img align=\"center\" src=\"figure/hp_cover.jpg\" width=\"150\"> | <img align=\"center\" src=\"figure/hp_desk.png\" width=\"300\">|\n",
    "|:--:|:--:|:--:|\n",
    "|(a) Text book.| (b) Harry Potter cover.| (c) HarryPotterized Text book|\n",
    "|| Fig 3.1 Warping for augmented reality. | |\n"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
=======
   "cell_type": "markdown",
   "id": "585b9e3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "id": "armed-guidance",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9dfb0d0359aee7c5091596a56c06782",
     "grade": false,
     "grade_id": "q3-code4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H Matrix: Cover to Desk [[ 7.47326954e-01 -3.40418527e-01  2.35993401e+02]\n",
      " [-7.09557804e-03  2.23570394e-01  1.92394970e+02]\n",
      " [ 7.99754575e-07 -9.18052165e-04  1.00000000e+00]]\n",
      "H Matrix: Desk to Cover: [[ 2.43038718e+00  7.51613809e-01 -7.18162053e+02]\n",
      " [ 4.40255023e-02  4.53733039e+00 -8.83349272e+02]\n",
      " [ 3.84739944e-05  4.16490488e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "\n",
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
    "def compositeH(H, template, img):\n",
    "    \"\"\"\n",
    "    Returns the composite image.\n",
    "    \n",
    "    INPUTS\n",
    "        H - homography matrix [3x3]\n",
    "        img - background image\n",
    "        template - template image to be warped\n",
    "\n",
    "    OUTPUTS\n",
    "        composite_img - composite image\n",
    "    \"\"\"\n",
    "\n",
    "    # ===============\n",
    "    # Hint: Create a composite image after warping the template image on top\n",
    "    # of the image using the homography\n",
<<<<<<< HEAD
=======
    "    composite_img = img\n",
    "    mask = np.ones_like(template)\n",
    "    warped_mask   = cv2.warpPerspective(mask, H, (img.shape[1], img.shape[0]))\n",
    "    warped_template = cv2.warpPerspective(template, H, (img.shape[1], img.shape[0]))\n",
    "    # Mask into the background image\n",
    "    composite_img[warped_mask == 1] = warped_template[warped_mask == 1]\n",
    "\n",
    "    # cv2.imshow(\"Mask\", warped_mask*255)\n",
    "    # cv2.waitKey()\n",
    "    # cv2.destroyAllWindows()\n",
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
    "\n",
    "    # Note that the homography we compute is from the image to the template;\n",
    "    # x_template = H2to1*x_photo\n",
    "    # For warping the template to the image, we need to invert it.\n",
    "    # ===============\n",
<<<<<<< HEAD
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return composite_img.astype(np.uint8)"
=======
    "    return composite_img.astype(np.uint8)\n",
    "\n",
    "# Load the images\n",
    "cv_desk = cv2.imread(\"data/pf_desk.jpg\")\n",
    "cv_cover = cv2.imread(\"data/pf_scan_scaled.jpg\")\n",
    "hp_cover = cv2.imread(\"data/hp_cover.jpg\")\n",
    "\n",
    "# Warp hp_cover to cv desk\n",
    "cv_desk_locs, cv_desk_dec = briefLite(cv_desk)\n",
    "cv_cover_locs, cv_cover_desc = briefLite(cv_cover)\n",
    "matches = briefMatch(cv_desk_dec, cv_cover_desc)\n",
    "np_matches = np.array(matches)\n",
    "H, inliers = computeH_ransac(np_matches, cv_desk_locs, cv_cover_locs)\n",
    "# warp = cv2.warpPerspective(hp_cover, H, (cv_desk.shape[0], cv_desk.shape[1]))\n",
    "# M, mask = cv2.findHomography(cv_desk_locs, cv_cover_locs, cv2.RANSAC,5.0)\n",
    "warp = cv2.warpPerspective(hp_cover, H, (cv_desk.shape[1], cv_desk.shape[0]))\n",
    "cv2.imshow(\"fsf\", warp)\n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Resize the hp cover to the cv cover size\n",
    "print(f\"H Matrix: Cover to Desk {H}\")\n",
    "Hinv = np.linalg.inv(H)\n",
    "print(f\"H Matrix: Desk to Cover: {Hinv/Hinv[-1,-1]}\")\n",
    "hp_cover = cv2.resize(hp_cover, dsize = (cv_cover.shape[1], cv_cover.shape[0]))\n",
    "composite_img = compositeH(H, img = cv_desk, template = hp_cover)\n",
    "cv2.imshow(\"Composite Image\", composite_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-royal",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "496a6f3ee7ce6def6cddce578b6b48eb",
     "grade": false,
     "grade_id": "q3-note4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### SVD Notes\n",
    "\n",
    "The Singular Value Decomposition (SVD) of a matrix $\\textbf{A}$ is expressed as:\n",
    "\\begin{equation*}\n",
    "\\mathbf{A} = U\\Sigma V^T\n",
    "\\end{equation*}\n",
    "Here, $U$ is a matrix of column vectors called the \"left singular vectors\". Similarly, $V$ is called the \"right singular vectors\". The matrix $\\Sigma$ is a diagonal matrix. Each diagonal element $\\sigma_i$ is called the \"singular value\" and these are sorted in order of magnitude. In our case, it is a $9\\times9$ matrix.\n",
    "\n",
    "   * If $\\sigma_9 = 0$, the system is _exactly-determined_, a homography exists and all points fit exactly.\n",
    "   * If $\\sigma_9 \\ge 0$, the system is _over-determined_. A homography exists but not all points fit exactly (they fit in the least-squares error sense). This value represents the goodness of fit.\n",
    "   * Usually, you will have at least four correspondences. If not, the system is _under-determined_. We will not deal with those here.\n",
    "\n",
    "The columns of $U$ are eigenvectors of $\\mathbf{AA}^T$. The columns of $V$ are the eigenvectors of $\\mathbf{A}^T\\mathbf{A}$. We can use this fact to solve for **h** in the equation **Ah = 0**.\n",
    "Using this knowledge, let us reformulate our problem of solving $\\mathbf{Ax} = \\mathbf{0}$. We want to minimize the error in solution in the least-squares sense. Ideally, the product $\\mathbf{Ah}$ should be 0. Thus the sum-squared error can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "f(\\mathbf{h}) = \\frac{1}{2}(\\mathbf{Ah} - \\mathbf{0})^{T}(\\mathbf{Ah} - \\mathbf{0})\\\\\n",
    "              = \\frac{1}{2}(\\mathbf{Ah})^{T} (\\mathbf{Ah})\\\\\n",
    "              = \\frac{1}{2}\\mathbf{h}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{h}\n",
    "\\end{equation}\n",
    "\n",
    "Minimizing this error with respect to **h**, we get:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d}{d\\mathbf{h}}f = 0\\\\\n",
    "\\implies \\frac{1}{2}(\\mathbf{A}^T\\mathbf{A} + (\\mathbf{A}^T\\mathbf{A})^T)\\mathbf{h} = 0\\\\\n",
    "\\mathbf{A}^T\\mathbf{Ah} = 0\n",
    "\\end{equation}\n",
    "\n",
    "This implies that the value of **h** equals the eigenvector corresponding to the zero eigenvalue (or closest to zero in case of noise). Thus, we choose the smallest eigenvalue of $\\mathbf{A}^T\\mathbf{A}$, which is $\\sigma_9$ in $\\Sigma$ and the least-squares solution to **Ah = 0** is the the corresponding eigenvector (in column 9 of the matrix **V**)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
=======
   "display_name": "Python 3.9.13 ('vision_conda')",
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.8"
=======
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab1be24f2b69fea20ab96b72f6a75a8226e3980324f891cd62f88ac8e8b7a219"
   }
>>>>>>> b340a2d4da61648edb00a3ce28ab68f64254d13e
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
