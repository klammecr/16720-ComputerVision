{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2ad6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43012640",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dbf31e0d75c9f2f596e56c940c6e5ee",
     "grade": false,
     "grade_id": "cell-a24dc0c293818e90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Bag of Visual Words - Assignment 2\n",
    "\n",
    "     Instructor: Kris Kitani                      TAs: Sheng-Yu, Jinkun, Rawal, Arka, Rohan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0861718",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "daacb6ab3a07d579036be18b4862aa73",
     "grade": false,
     "grade_id": "cell-5bf9175efa654233",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Building a Recognition System\n",
    "We have formed a convenient way to represent images for recognition. We will now produce a basic recognition system with spatial pyramid matching. The goal of the system is presented below,\n",
    "given an image, classify (\\ie recognize/name) the scene where the image was taken. \n",
    "\n",
    "<img align=\"center\" src=\"figures/teaser/teaser.png\" width=\"800\">\n",
    "\n",
    "Traditional classification problems follow two phases: training and testing.\n",
    "At training time, the computer is given a pile of formatted data (\\ie, a collection\n",
    "of feature vectors) with corresponding labels (\\eg, ``desert``, ``kitchen``) and\n",
    "then builds a model of how the data relates to the labels:\n",
    "``if green, then kitchen``. At test time, the computer takes features and uses these rules to infer the label:\n",
    "\\eg, ``this is green, therefore it is kitchen``.\n",
    "\n",
    "In this assignment, we will use the simplest classification model: nearest neighbor.\n",
    "At test time, we will simply look at the query's nearest neighbor in the training set\n",
    "and transfer that label. In this example, you will be looking\n",
    "at the query image and \n",
    "looking up its nearest neighbor in a collection of training images whose labels are already known. This approach works\n",
    "surprisingly well given a huge amount of data, \\eg, a very cool graphics applications from [1]. \n",
    "\n",
    "The key components of any nearest-neighbor system are: \n",
    "* $features$ (how do you represent your instances?)\n",
    "* $similarity$ (how do you compare instances in the feature space?)\n",
    "\n",
    "You will implement both in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a8656b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec7d40f847d0a8888a9c579671ddf041",
     "grade": false,
     "grade_id": "cell-24621a038b7f3018",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import numpy as np\n",
    "import skimage\n",
    "import multiprocess\n",
    "import threading\n",
    "import queue\n",
    "import os,time\n",
    "import math\n",
    "import ipykernel\n",
    "from p1 import get_visual_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e53d1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42b93f2fd34d13d0deb697d261a757d5",
     "grade": false,
     "grade_id": "cell-7c3a5b2d9b8ce219",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## For Autograding P2, ensure uploading `trained_system.npz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a73b2a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dfe39f2b5d232f420d89dfc6a1c8b1d",
     "grade": false,
     "grade_id": "cell-abf0004ccc069506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.1 (10 Points -> 5 Autograder + 5 WriteUp)\n",
    "We will first represent an image with a bag of words approach. In each image, we simply look at\n",
    "how often each word appears. Write the function\n",
    "```\n",
    "            def get_feature_from_wordmap(wordmap,dict_size):\n",
    "```\n",
    "that extracts the histogram (Look into ``numpy.histogram()``) of visual words within the given image\n",
    "(\\ie, the bag of visual words). \n",
    "As inputs, the function will take:\n",
    "\n",
    "* $wordmap$ is a $H$ $\\times$ $W$ image containing the IDs of the visual words\n",
    "* $dict\\_size$ is the maximum visual word ID (\\ie, the number of visual words, the dictionary size). Notice that your histogram should have $dict\\_size$ bins, corresponding to how often that each word occurs. \n",
    "\n",
    "As output, the function will return $hist$, a $dict\\_size$ histogram that is $L_1$ normalized, (i.e., the sum equals $1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29689d48",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1254416f040933e0666d2047ffa467e5",
     "grade": false,
     "grade_id": "cell-8e9543ec71e3c588",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from p2_1 import get_feature_from_wordmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c65cf8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68d581bfafe37f38106fb00b90fde05b",
     "grade": false,
     "grade_id": "cell-e84e8b8406598ee0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font color=\"blue\">**For 5 Images, load visual word maps, visualize their histogram, and include it in the write up.**</font> This will help you verifying that your function is working correctly before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923765a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb27cfed4049eea97153dcf591bb4146",
     "grade": false,
     "grade_id": "cell-420ecef2e3112019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multi-resolution: Spatial Pyramid Matching\n",
    "\n",
    "Bag of words is simple and efficient, but it discards information about the spatial structure of the image and this information is often valuable. One way to alleviate this issue is to use spatial pyramid matching [2]. The general idea is to divide the image into a small number of cells, and concatenate the histogram of each of these cells to the histogram of the original image, with a suitable weight. \n",
    "\n",
    "Here we will implement a popular scheme that chops the image into $2^l\\times2^l$ cells where $l$ is the layer number. We treat each cell as a small image and count how often each visual word appears. This results in a histogram for every single cell in every layer. Finally to represent the entire image, we concatenate all the histograms together. If there are $L+1$ layers and $K$ visual words, the resulting vector has dimensionality $K\\sum_{l=0}^L{4^l} = K\\left(4^{(L+1)}-1\\right)/3$.\n",
    "\n",
    "Now comes the weighting scheme. Note that when concatenating all the histograms, histograms from different levels are assigned different weights. Typically (and in the original work [2]), features from layer $l$ gets half the weight of features from layer $l+1$, with the exception of layer 0, which is assigned a weight equal to layer 1. A popular choice is for layer $0$ and layer $1$ the weight is set to $2^{-L}$, and for the rest it is set to $2^{l-L-1}$ (\\eg, in a three layer spatial pyramid, $L=2$ and weights are set to $1/4$, $1/4$ and $1/2$ for layer 0, 1 and 2 respectively, see Fig. 7). Take level 2 as an example, there will be 16 histograms in total, each has a norm equal to one. You should concatenate these histograms, normalize this layer (multiply the concatenated vector by 1/16), and apply the 1/2 layer weight of level 2 on top of that. Note that following this operation, concatenating the weighted features of each layer will result in a final vector of norm equal to 1.\n",
    "\n",
    "<img align=\"center\" src=\"figures/spm.jpg\" width=\"600\">\n",
    "<figcaption align = \"center\"><b>Figure 7. Spatial Pyramid Matching: From [2]. Toy example of a pyramid for L = 2. The image has three visual words, indicated by circles, diamonds, and crosses. We subdivide the image at three different levels of resolution. For each level of resolution and each channel, we count the features that fall in each spatial bin. Finally, weight each spatial histogram.}</b></figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b84b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e7ceda3fd88f1fee5ddf1ff7b6f928c",
     "grade": false,
     "grade_id": "cell-37520ce1e3b2405a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.2.1 (15 Points Autograder)\n",
    "\n",
    "Create a function that form a multi-resolution representation of the given image.\n",
    "```\n",
    "            def get_feature_from_wordmap_SPM(wordmap,layer_num,dict_size):\n",
    "```\n",
    "As inputs, the function will take:\n",
    "\n",
    "* **layer_num** the number of layers in the spatial pyramid, \\ie, $L+1$\n",
    "* **wordmap** is a $H$ $\\times$ $W$ image containing the IDs (\\ie index) of the visual words\n",
    "* **dict_size** is the maximum visual word ID (\\ie, the number of visual words, the dictionary size)\n",
    "\n",
    "As output, the function will return hist_all, a vector that is $L_1$ normalized. **Please use a 3-layer spatial pyramid ($L=2$) for all the following recognition tasks.**\n",
    "\n",
    "One small hint for efficiency: a lot of computation can be saved if you first compute the histograms of the _finest layer_, because the histograms of coarser layers can then be aggregated from finer ones. Make sure you normalize the histogram after aggregation.\n",
    "\n",
    "**Note for Autograder :** Ensure that final $hist\\_all$ (the output of `get_feature_from_wordmap_SPM`) has histogram features arranged from Loweset Level (global features) to Highest Level (finest features). Example: the output array should **first contain the histogram for Level 0, followed by Level 1, and then Level 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84e34ee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ea2abb5b089e2e2a54f5eacfcb47505",
     "grade": false,
     "grade_id": "cell-1ce0fa9511c64ad7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from p2_1 import get_feature_from_wordmap_SPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b2a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.07258065e-03, 1.85618280e-03, 5.91397849e-05, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.07526882e-05])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"./data/aquarium/sun_aydaknxraiwghvmi.jpg\")\n",
    "# Load the visual word dictionary\n",
    "visual_word_dict = np.load(\"dictionary.npy\")\n",
    "visual_image = get_visual_words(img, visual_word_dict)\n",
    "get_feature_from_wordmap_SPM(visual_image, 3, visual_word_dict.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28320ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04032ab193e9ca78f8fe4c9b8ee94b5e",
     "grade": false,
     "grade_id": "cell-66d373829f0267b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Comparing images\n",
    "\n",
    "\n",
    "We will also need a way of comparing images to find the _nearest_ instance in the training data. In this assignment, we'll use the histogram intersection similarity. The histogram intersection similarity between two histograms is the sum of the minimum value of each corresponding bins.\n",
    "\n",
    "Note that since this is a similarity, you want the $largest$ value to find the _nearest_ instance.\n",
    "\n",
    "#### Q2.3.1 (10 Points Autograder)\n",
    "Create the function\n",
    "```\n",
    "                def distance_to_set(word_hist,histograms):\n",
    "```\n",
    "where $word\\_hist$ is a $K\\left(4^{(L+1)}-1\\right)/3$ vector and $histograms$ is a $T \\times K\\left(4^{(L+1)}-1\\right)/3$ matrix containing $T$ features from $T$ training samples concatenated along the rows. This function returns the histogram intersection similarity between $word\\_hist$ and each training sample as a vector of length $T$. Since this is called every time you want to look up a classification, you want this to be fast, so doing a for-loop over tens of thousands of histograms is a very bad idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265eeb4f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65968a4a820824572f5715b4776866b4",
     "grade": false,
     "grade_id": "cell-465ba3be1342934c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from p2_1 import distance_to_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f74ff82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([0.1,0.4,0.5])\n",
    "B = np.array([[0.2,0.3,0.5],[0.8,0.1,0.1]])\n",
    "sim = distance_to_set(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a23d65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6e3eb69fe9118a07d7c0854176fb7bb",
     "grade": false,
     "grade_id": "cell-5d13fb8f4aab2c9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2.4 Building a Model of the Visual World\n",
    "\n",
    "Now that we've obtained a representation for each image, and defined a similarity measure to compare two spatial pyramids, we want to put everything up to now together.\n",
    "\n",
    "You will need to load the training file names from `data/train_data.npz` and the filter bank and visual word dictionary from `dictionary.npy`.\n",
    "You will save everything to a `.npz` numpy-formated (use `np.savez`) file named `trained_system.npz`. Included will be:\n",
    "\n",
    "\n",
    "1. $dictionary$: your visual word dictionary.\n",
    "2. $features$: a $N \\times  K\\left(4^{(L+1)}-1\\right)/3$ matrix containing all of the histograms of the $N$ training images in the data set. A dictionary with $150$ words will make a ``train_features`` matrix of size $1000 \\times 3150$.\n",
    "3. $labels$: an $N$ vector containing the labels of each of the images. ( ``features[i]`` will correspond to label ``labels[i]``).\n",
    "4. $SPM\\_layer\\_num$: the number of spatial pyramid layers you used to extract the features for the training images.\n",
    "\n",
    "We have provided you with the names of the training images in ``data/train_data.npz``.\n",
    "You want to use the dictionary entry ``image_names`` for training.\n",
    "You are also provided the names of the test images in ``data/test_data.npz``, which is structured in the same way as the training data; however, _you cannot use the testing images for training._\n",
    "\n",
    "If it's any helpful, the below table lists the class names that correspond to the label indices:\n",
    "\n",
    "| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n",
    "| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n",
    "|aquarium | park | desert | highway | kitchen | laundromat | waterfall | windmill|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd5b1c",
   "metadata": {},
   "source": [
    "#### Q2.4.1 (15 Points Autograder)\n",
    "Implement the function\n",
    "```\n",
    "                def build_recognition_system():\n",
    "```\n",
    "that produces ``trained_system.npz``.\n",
    "\n",
    "Implement \n",
    "```\n",
    "                def get_image_feature(file_path,dictionary,layer_num,K):\n",
    "```\n",
    "that load image, extract word map from the image, compute SPM feature and return the computed feature. Use this function in your ``build_recognition_system()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e5f85d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70bf1a70ee97f9b567d81581a8c94d8d",
     "grade": false,
     "grade_id": "cell-bd6c5a8aa3b427b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from p2_1 import get_image_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8404204",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e007040b160b137c692483b0b496499",
     "grade": false,
     "grade_id": "cell-5465a0a46dfde2c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_recognition_system(num_workers = 8):\n",
    "    '''\n",
    "    Creates a trained recognition system by generating training features from all training images.\n",
    "\n",
    "    [input]\n",
    "    * num_workers: number of workers to process in parallel\n",
    "\n",
    "    [saved]\n",
    "    * features: numpy.ndarray of shape (N,M)\n",
    "    * labels: numpy.ndarray of shape (N)\n",
    "    * dictionary: numpy.ndarray of shape (K,3F)\n",
    "    * SPM_layer_num: number of spatial pyramid layers\n",
    "    '''\n",
    "\n",
    "    # Define the number of layers\n",
    "    spm_layers = 3\n",
    "\n",
    "    # Load the dictionary and training data\n",
    "    train_data = np.load(\"./data/train_data.npz\")\n",
    "    dictionary = np.load(\"dictionary.npy\")\n",
    "\n",
    "    # Parse out the training files\n",
    "    train_files = train_data.get(\"files\")\n",
    "    if train_files is None:\n",
    "        raise ValueError(\"No valid training files available :(\")\n",
    "    train_files = [\"./data/\" + str(file) for file in train_files]\n",
    "\n",
    "    # Parse out the training labels\n",
    "    labels = train_data.get(\"labels\")\n",
    "    if labels is None:\n",
    "        raise ValueError(\"No valid labels available :(\")\n",
    "\n",
    "    # Gather arguments for multiprocessing\n",
    "    args = []\n",
    "    for idx, train_sample in enumerate(train_files):\n",
    "        args.append((train_sample, dictionary, spm_layers, dictionary.shape[0]))\n",
    "\n",
    "    # NxM array of the training features\n",
    "    training_features = np.zeros((len(args), int(dictionary.shape[0] / 3 * (4**(spm_layers)-1))))\n",
    "\n",
    "    # Multiprocess getting the image features\n",
    "    result_dict = {}\n",
    "    with multiprocess.Pool(num_workers) as p:\n",
    "        # Get the result\n",
    "        result = p.starmap(get_image_feature, args)\n",
    "\n",
    "        for r in result:\n",
    "            # Associate where to put it in the output list\n",
    "            idx = np.argwhere(np.array(train_files) == r[0])\n",
    "\n",
    "            # Put it in the output list\n",
    "            training_features[idx[0]] = r[1]\n",
    "\n",
    "    np.savez('trained_system.npz', features=training_features,\n",
    "                                    labels=labels,\n",
    "                                    dictionary=dictionary,\n",
    "                                    SPM_layer_num=spm_layers)\n",
    "\n",
    "\n",
    "# build_recognition_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac55f32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db3f9591ac0e2778ca5ef665c6227fa6",
     "grade": false,
     "grade_id": "cell-63d0143d4e3d0c6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### References\n",
    "\n",
    "[1]  James Hays and Alexei A Efros. Scene completion using millions of photographs.ACM Transactions onGraphics (SIGGRAPH 2007), 26(3), 2007.\n",
    "\n",
    "[2]  S. Lazebnik, C. Schmid, and J. Ponce. Beyond bags of features: Spatial pyramid matching for recogniz-ing natural scene categories.  InComputer Vision and Pattern Recognition (CVPR), 2006 IEEE Conferenceon, volume 2, pages 2169–2178, 2006.\n",
    "\n",
    "[3]  Jian xiong Xiao, J. Hays, K. Ehinger, A. Oliva, and A. Torralba. Sun database: Large-scale scene recogni-tion from abbey to zoo.2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition,pages 3485–3492, 2010.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f1914",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35ee79b5e5fccba897d0d2d9dc949c9d",
     "grade": true,
     "grade_id": "q_2_1_1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a56989",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebeebf6212f93c0c3223f32582217689",
     "grade": true,
     "grade_id": "q_2_2_1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172fb7b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e93e34336483b7c51eb11230b99a89f",
     "grade": true,
     "grade_id": "q_2_3_1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326e1ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "870554a8fedbc04b85337e1ded2ef277",
     "grade": true,
     "grade_id": "q_2_4_1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75798c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('vision_conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab1be24f2b69fea20ab96b72f6a75a8226e3980324f891cd62f88ac8e8b7a219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
